{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([9, 172]), torch.Size([9, 171]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "dataset = load_from_disk(\"tokenized_dataset\")\n",
    "dataset.shuffle(42)\n",
    "dataset[\"full\"][0][\"labels\"].shape, dataset[\"full\"][0][\"tokens\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # Get max length in batch\n",
    "    max_input_len = max(x['tokens'].shape[1] for x in batch)\n",
    "    \n",
    "    # Prepare empty tensors for batch\n",
    "    tokens = torch.full((len(batch), 9, max_input_len), fill_value=2, dtype=torch.long)  # 2 for <|im_end|>\n",
    "    labels = torch.full((len(batch), 9, max_input_len + 1), fill_value=-100, dtype=torch.long)\n",
    "    \n",
    "    # Fill in actual values\n",
    "    for i, item in enumerate(batch):\n",
    "        seq_len = item['tokens'].shape[1]\n",
    "        tokens[i, :, :seq_len] = item['tokens'].clone().detach()\n",
    "        labels[i, :, :seq_len+1] = item['labels'].clone().detach()\n",
    "    \n",
    "    return {'tokens': tokens, 'labels': labels}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded text:\n",
      "<|im_start|>system\n",
      "Speak out the provided text<|im_end|>\n",
      "<|im_start|>user\n",
      "whence it deduced the practice and condition of every prison that replied.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<|semantic:1415|><|semantic:268|><|semantic:561|><|semantic:523|><|semantic:1300|><|semantic:942|><|semantic:170|><|semantic:1309|><|semantic:54|><|semantic:1269|><|semantic:1274|><|semantic:1326|><|semantic:1658|><|semantic:366|><|semantic:366|><|semantic:313|><|semantic:1899|><|semantic:146|><|semantic:238|><|semantic:1228|><|semantic:1534|><|semantic:300|><|semantic:1558|><|semantic:1054|><|semantic:1385|><|semantic:54|><|semantic:1379|><|semantic:1840|><|semantic:1517|><|semantic:410|><|semantic:1781|><|semantic:1508|><|semantic:552|><|semantic:1600|><|semantic:1600|><|semantic:1639|><|semantic:313|><|semantic:1997|><|semantic:1985|><|semantic:819|><|semantic:150|><|semantic:1487|><|semantic:1612|><|semantic:325|><|semantic:1910|><|semantic:858|><|semantic:157|><|semantic:157|><|semantic:839|><|semantic:1628|><|semantic:56|><|semantic:1640|><|semantic:769|><|semantic:666|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|>\n",
      "\n",
      "Shapes:\n",
      "Full batch shape: torch.Size([8, 9, 180])\n",
      "First item shape: torch.Size([9, 180])\n",
      "Semantic tokens shape: torch.Size([180])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"../checkpoints/smoltts\")\n",
    "\n",
    "# Setup dataloader\n",
    "dataloader = DataLoader(dataset['full'], batch_size=8, collate_fn=collate_fn, shuffle=True)\n",
    "\n",
    "# Get first batch\n",
    "batch = next(iter(dataloader))\n",
    "\n",
    "# Look at first item in batch\n",
    "first_item = batch['tokens'][0]  # Should be [9, seq_len]\n",
    "\n",
    "# Get semantic tokens (first row)\n",
    "semantic_tokens = first_item[0]  # Just the first index for semantic tokens\n",
    "\n",
    "# Remove padding (zeros) if any\n",
    "semantic_tokens = semantic_tokens[semantic_tokens != 0]\n",
    "\n",
    "# Decode\n",
    "decoded = tokenizer.decode(semantic_tokens)\n",
    "print(\"Decoded text:\")\n",
    "print(decoded)\n",
    "\n",
    "# Optional: print shapes to verify\n",
    "print(\"\\nShapes:\")\n",
    "print(f\"Full batch shape: {batch['tokens'].shape}\")\n",
    "print(f\"First item shape: {first_item.shape}\")\n",
    "print(f\"Semantic tokens shape: {semantic_tokens.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from ../checkpoints/smoltts, config: DualARModelArgs(model_type='dual_ar', vocab_size=51200, n_layer=30, n_head=9, dim=576, intermediate_size=1536, n_local_heads=3, head_dim=64, rope_base=100000, norm_eps=1e-05, max_seq_len=8192, dropout=0.0, tie_word_embeddings=True, attention_qkv_bias=False, codebook_size=2048, num_codebooks=8, use_gradient_checkpointing=True, initializer_range=0.041666666666666664, is_reward_model=False, share_codebook_embeddings=True, scale_codebook_embeddings=False, n_fast_layer=4, fast_dim=576, fast_n_head=9, fast_n_local_heads=3, fast_head_dim=64, fast_intermediate_size=1536, fast_attention_qkv_bias=False)\n",
      "Loaded weights with error: <All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "from model.dual_ar import DualARTransformer\n",
    "\n",
    "model = DualARTransformer.from_pretrained(\"../checkpoints/smoltts\", load_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1637.5"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BSZ = 8\n",
    "len(dataset[\"full\"]) / BSZ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
